# Awesome-deep-multimodal-reasoning
Collect the awesome works evolved around reasoning models like O1/R1 in multimodal domain.

### Papers/Projects
#### Visual Understanding

- **[Image]** Visual Reinforcement Fine-Tuning [[paper]](https://arxiv.org/abs/2503.01785) [[code]](https://github.com/Liuziyu77/Visual-RFT) [[ViRFT]](https://huggingface.co/collections/laolao77/virft-datasets-67bc271b6f2833eccc0651df)
- **[Image]** VLM-R1: A stable and generalizable R1-style Large Vision-Language Model [[code]](https://github.com/om-ai-lab/VLM-R1) [[VLM-R1 Data]]((https://huggingface.co/datasets/omlab/VLM-R1) )
- **[Video]** Video-R1: Towards Super Reasoning Ability in Video Understanding [[code]](https://github.com/tulerfeng/Video-R1) 
- **[Video]** Open R1 Video [[code]](https://github.com/Wang-Xiaodong1899/Open-R1-Video) [[open-r1-video-4k]](https://huggingface.co/datasets/Xiaodong/open-r1-video-4k)
- **[Omni]** MM-RLHF: The Next Step Forward in Multimodal LLM Alignment [[paper]](https://arxiv.org/abs/2502.10391) [[code]](https://github.com/Kwai-YuanQi/MM-RLHF) [[MM-RLHF Data]](https://huggingface.co/datasets/yifanzhang114/MM-RLHF) [[MM-RLHF-RewardBench]](https://huggingface.co/datasets/yifanzhang114/MM-RLHF-RewardBench)
- **[Omni]** R1-Omni: Explainable Omni-Multimodal Emotion Recognition with Reinforcement Learning [[paper]](https://arxiv.org/abs/2503.05379) [[code]](https://github.com/HumanMLLM/R1-Omni)

#### Visual Reasoning

- MM-EUREKA: Exploring Visual Aha Moment with Rule-based Large-scale Reinforcement Learning  [[paper]](https://github.com/ModalMinds/MM-EUREKA/blob/main/MM_Eureka_paper.pdf) [[code]](https://github.com/ModalMinds/MM-EUREKA) [[MM-Eureka-Dataset]](https://huggingface.co/datasets/FanqingM/MM-Eureka-Dataset/tree/main)
- Multimodal Open R1 [[code]](https://github.com/EvolvingLMMs-Lab/open-r1-multimodal) [[multimodal-open-r1-8k-verified]](https://huggingface.co/datasets/lmms-lab/multimodal-open-r1-8k-verified) 
- VL-Thinking: An R1-Derived Visual Instruction Tuning Dataset for Thinkable LVLMs [[code]](https://github.com/UCSC-VLAA/VL-Thinking) [[VL-Thinking]](https://huggingface.co/datasets/UCSC-VLAA/VL-Thinking)
- R1-V: Reinforcing Super Generalization Ability in Vision Language Models with Less Than $3 [[code]](https://github.com/Deep-Agent/R1-V) [[R1V Training Dataset: CLEVR-70k-Counting]](https://huggingface.co/datasets/leonardPKU/clevr_cogen_a_train) [[R1V Training Dataset: CLEVR-70k-Complex]](https://huggingface.co/datasets/MMInstruction/Clevr_CoGenT_TrainA_70K_Complex) [[R1V Training Dataset: GEOQA-8k]](https://huggingface.co/datasets/leonardPKU/GEOQA_R1V_Train_8K) [[R1-Distilled Visual Reasoning Dataset]](https://huggingface.co/datasets/MMInstruction/Clevr_CoGenT_TrainA_R1)
- LlamaV-o1: Rethinking Step-by-step Visual Reasoning in LLMs [[paper]](https://arxiv.org/abs/2501.06186) [[code]](https://github.com/mbzuai-oryx/LlamaV-o1) [[VRC-Bench]](https://huggingface.co/datasets/omkarthawakar/VRC-Bench) 
- Imagine while Reasoning in Space: Multimodal Visualization-of-Thought [[paper]](https://arxiv.org/abs/2501.07542)
- Vision-R1: Incentivizing Reasoning Capability in Multimodal Large Language Models [[paper]](https://arxiv.org/abs/2503.06749) [[code]](https://github.com/Osilly/Vision-R1/tree/main)

#### Medical

- MedVLM-R1: Incentivizing Medical Reasoning Capability of Vision-Language Models (VLMs) via Reinforcement Learning [[paper]](https://arxiv.org/abs/2502.19634v1)
- HuatuoGPT-o1, Towards Medical Complex Reasoning with LLMs [[paper]](https://arxiv.org/abs/2412.18925) [[code]](https://github.com/FreedomIntelligence/HuatuoGPT-o1) [[medical-o1-reasoning-SFT]](https://huggingface.co/datasets/FreedomIntelligence/medical-o1-reasoning-SFT)

### Datasets

- [Training] [LLaVA-R1-100k](https://www.modelscope.cn/datasets/modelscope/LLaVA-R1-100k) - LLaVA多模态Reasoning数据集
- [Benchmarking] [MMMU-Reasoning-R1-Distill-Validation](https://www.modelscope.cn/datasets/modelscope/MMMU-Reasoning-Distill-Validation) - MMMU-满血版R1蒸馏多模态Reasoning验证集

### Acknowledgement

[modelscope/awesome-deep-reasoning](https://github.com/modelscope/awesome-deep-reasoning)


