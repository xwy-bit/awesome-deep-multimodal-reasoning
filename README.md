# Awesome-deep-multimodal-reasoning
Collect the awesome works evolved around reasoning models like O1/R1 in multimodal domain.

### Papers/Projects
#### Visual Understanding

- **[Image]** Visual Reinforcement Fine-Tuning [[paper]](https://arxiv.org/abs/2503.01785) [[code]](https://github.com/Liuziyu77/Visual-RFT)
- **[Image]** VLM-R1: A stable and generalizable R1-style Large Vision-Language Model [[code]](https://github.com/om-ai-lab/VLM-R1) 
- **[Video]** Video-R1: Towards Super Reasoning Ability in Video Understanding [[code]](https://github.com/tulerfeng/Video-R1) 
- **[Video]** Open R1 Video [[code]](https://github.com/Wang-Xiaodong1899/Open-R1-Video)
- **[Image&Video]** MM-RLHF: The Next Step Forward in Multimodal LLM Alignment [[paper]](https://arxiv.org/abs/2502.10391) [[code]](https://github.com/Kwai-YuanQi/MM-RLHF)

#### Visual Reasoning

- MM-EUREKA: Exploring Visual Aha Moment with Rule-based Large-scale Reinforcement Learning  [[paper]](https://github.com/ModalMinds/MM-EUREKA/blob/main/MM_Eureka_paper.pdf) [[code]](https://github.com/ModalMinds/MM-EUREKA)
- Multimodal Open R1 [[code]](https://github.com/EvolvingLMMs-Lab/open-r1-multimodal) 
- VL-Thinking: An R1-Derived Visual Instruction Tuning Dataset for Thinkable LVLMs [[code]](https://github.com/UCSC-VLAA/VL-Thinking)
- R1-V: Reinforcing Super Generalization Ability in Vision Language Models with Less Than $3 [[code]](https://github.com/Deep-Agent/R1-V)
- LlamaV-o1: Rethinking Step-by-step Visual Reasoning in LLMs [[paper]](https://arxiv.org/abs/2501.06186) [[code]](https://github.com/mbzuai-oryx/LlamaV-o1)


- Imagine while Reasoning in Space: Multimodal Visualization-of-Thought [[paper]](https://arxiv.org/abs/2501.07542)

#### Medical

- MedVLM-R1: Incentivizing Medical Reasoning Capability of Vision-Language Models (VLMs) via Reinforcement Learning [[paper]](https://arxiv.org/abs/2502.19634v1)
- HuatuoGPT-o1, Towards Medical Complex Reasoning with LLMs [[paper]](https://arxiv.org/abs/2412.18925) [[code]](https://github.com/FreedomIntelligence/HuatuoGPT-o1) [[data]](https://huggingface.co/datasets/FreedomIntelligence/medical-o1-reasoning-SFT)

### Datasets

- [Training] [LLaVA-R1-100k](https://www.modelscope.cn/datasets/modelscope/LLaVA-R1-100k) - LLaVA多模态Reasoning数据集
- [Training] [clevr_cogen_a_train](https://huggingface.co/datasets/leonardPKU/clevr_cogen_a_train) \- A R1-distilled visual reasoning dataset.
- [Training] [Clevr_CoGenT_TrainA_R1](https://huggingface.co/datasets/MMInstruction/Clevr_CoGenT_TrainA_R1) - A multi-modal dataset for training MM R1 model.
- [Benchmarking] [MMMU-Reasoning-R1-Distill-Validation](https://www.modelscope.cn/datasets/modelscope/MMMU-Reasoning-Distill-Validation) - MMMU-满血版R1蒸馏多模态Reasoning验证集

### Acknowledgement

[modelscope/awesome-deep-reasoning](https://github.com/modelscope/awesome-deep-reasoning)


